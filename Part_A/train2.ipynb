{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class Nature12KDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"../../inaturalist_12K\", batch_size=64, image_size=(512, 512), data_aug=False):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.data_aug = data_aug\n",
    "\n",
    "    @staticmethod\n",
    "    def get_transform(image_size, data_aug=False):\n",
    "        transform_list = [transforms.Resize(image_size)]\n",
    "\n",
    "        if data_aug:\n",
    "            transform_list += [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "            ]\n",
    "\n",
    "        transform_list += [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_transform = self.get_transform(self.image_size, self.data_aug)\n",
    "        test_transform = self.get_transform(self.image_size, False)\n",
    "\n",
    "        # Load train and test datasets\n",
    "        full_train = datasets.ImageFolder(os.path.join(self.data_dir, \"train\"), transform=train_transform)\n",
    "        test_set = datasets.ImageFolder(os.path.join(self.data_dir, \"test\"), transform=test_transform)\n",
    "\n",
    "        # Split train into train + val (80-20 split)\n",
    "        val_size = int(0.2 * len(full_train))\n",
    "        train_size = len(full_train) - val_size\n",
    "        self.train_set, self.val_set = random_split(full_train, [train_size, val_size])\n",
    "\n",
    "        self.test_set = test_set\n",
    "        self.class_names = full_train.classes\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 conv_filters,\n",
    "                 kernel_sizes,\n",
    "                 activation,\n",
    "                 dense_neurons,\n",
    "                 num_classes,\n",
    "                 lr,\n",
    "                 batch_norm=False,        # ← ADD THIS\n",
    "                 dropout=0.0):            # ← AND THIS IF NOT PRESENT\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        self.activation_fn = self._get_activation_fn(activation)\n",
    "\n",
    "        # Conv Layers\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        for out_channels, ksize in zip(conv_filters, kernel_sizes):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=ksize, padding=ksize // 2))\n",
    "    \n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "    \n",
    "            layers.append(self._get_activation_fn(activation))\n",
    "            layers.append(nn.MaxPool2d(2, 2))\n",
    "\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout2d(dropout))\n",
    "    \n",
    "            in_channels = out_channels\n",
    "\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(*layers)\n",
    "\n",
    "        # Flattened dim\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_channels, 256, 256)\n",
    "            dummy_output = self.conv_blocks(dummy_input)\n",
    "            flatten_dim = dummy_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Fully connected\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(flatten_dim, dense_neurons),\n",
    "            self.activation_fn,\n",
    "            nn.Linear(dense_neurons, num_classes)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def _get_activation_fn(self, name):\n",
    "        name = name.lower()\n",
    "        if name == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif name == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif name == 'silu':\n",
    "            return nn.SiLU()\n",
    "        elif name == 'mish':\n",
    "            return nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        # self.log(\"test_loss\", loss)\n",
    "        # self.log(\"test_acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    data_module = Nature12KDataModule(\n",
    "        data_dir=\"../../inaturalist_12K\",  # ✅ Correct path here\n",
    "        batch_size=config.batch_size,\n",
    "        image_size=(256, 256),\n",
    "        data_aug=config.data_augmentation\n",
    "    )\n",
    "\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup()\n",
    "\n",
    "    model = CNN(\n",
    "        input_channels=3,\n",
    "        conv_filters=config.conv_filters,\n",
    "        kernel_sizes=config.kernel_sizes,\n",
    "        activation=config.activation,\n",
    "        dense_neurons=config.dense_neurons,\n",
    "        num_classes=len(data_module.class_names),\n",
    "        lr=config.lr,\n",
    "        batch_norm=config.batch_norm,\n",
    "        dropout=config.dropout\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(project=wandb.run.project, name=wandb.run.name)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=5,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        log_every_n_steps=10,\n",
    "        logger=wandb_logger  # ✅ Correct logger\n",
    "    )\n",
    "\n",
    "    print(\"🚀 Training model...\")\n",
    "    trainer.fit(model, data_module.train_dataloader(), data_module.val_dataloader())\n",
    "\n",
    "    print(\"🧪 Evaluating on test set...\")\n",
    "    trainer.test(model, data_module.test_dataloader())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_sweep():\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': 'val_acc',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'conv_filters': {\n",
    "                'values': [[32,64 , 128]]\n",
    "            },\n",
    "            'kernel_sizes': {\n",
    "                'values': [\n",
    "                    [3, 3, 3],\n",
    "                ]\n",
    "            },\n",
    "            'activation': {\n",
    "                'values': ['relu', 'gelu', 'silu', 'mish']\n",
    "            },\n",
    "            'dense_neurons': {\n",
    "                'values': [512, 256]\n",
    "            },\n",
    "            'lr': {\n",
    "                'min': 0.01,\n",
    "                'max': 0.1\n",
    "            },\n",
    "            'batch_norm': {\n",
    "                'values': [True, False]\n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.2, 0.3]\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [8]\n",
    "            },\n",
    "            'data_augmentation': {\n",
    "                'values': [True, False]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config, project='iNaturalist_CNN_Sweep')\n",
    "    wandb.agent(sweep_id, function=train, count=50)\n",
    "    # 6mpxfky1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 3pzarrcm\n",
      "Sweep URL: https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h9uoeuoi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [3, 3, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03444723990965818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24s019\u001b[0m (\u001b[33mda24s019-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Documents/Books/DA24S019_Assignment_2/Part_A/wandb/run-20250412_152218-h9uoeuoi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/h9uoeuoi' target=\"_blank\">splendid-sweep-1</a></strong> to <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/h9uoeuoi' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/h9uoeuoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | activation_fn | Mish             | 0      | train\n",
      "1 | conv_blocks   | Sequential       | 93.2 K | train\n",
      "2 | classifier    | Sequential       | 33.6 M | train\n",
      "3 | loss_fn       | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------------\n",
      "33.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.7 M    Total params\n",
      "134.602   Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'conv_filters' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'kernel_sizes' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dense_neurons' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_norm' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68758671940c4b19b53e0ac5b1654368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc080de1326a40ddaf7c72e9458fce69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad88cdaf8d49b5bcd9b5d631bba610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deec676ffae2464ca741a723dc33ba86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2992b7d9c06493b9fc3ce6eafa0e34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d7c064b4734634b5352a4f4f07f815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6439da27db428da4e875536420e0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'conv_filters' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'kernel_sizes' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dense_neurons' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_norm' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421f245606ec46ddb704f4f63e0c5016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆█████</td></tr><tr><td>train_acc</td><td>▃▃▃▆▆▁▁▆▁▁▁▃▁▁▃▁▆▃▁▁▃▃▆█▃▁▃▃▁▁▆▁▁▃▃▃▁▃▃▃</td></tr><tr><td>train_loss</td><td>▅▅▄██▇▅▇▆▅▅▅▅▆▄▆▆▄▇▃▆▆▅▅▁▄▆▇▄▄▅▃▆▇▆▅▆█▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█████</td></tr><tr><td>val_acc</td><td>▂▄▁█▂</td></tr><tr><td>val_loss</td><td>▇▃█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>0</td></tr><tr><td>train_loss</td><td>2.39292</td></tr><tr><td>trainer/global_step</td><td>4999</td></tr><tr><td>val_acc</td><td>0.09655</td></tr><tr><td>val_loss</td><td>2.30862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-1</strong> at: <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/h9uoeuoi' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/h9uoeuoi</a><br> View project at: <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250412_152218-h9uoeuoi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s1w7lggt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [3, 3, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.031067390713818963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Documents/Books/DA24S019_Assignment_2/Part_A/wandb/run-20250412_154927-s1w7lggt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/s1w7lggt' target=\"_blank\">soft-sweep-2</a></strong> to <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/sweeps/3pzarrcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/s1w7lggt' target=\"_blank\">https://wandb.ai/da24s019-indian-institute-of-technology-madras/iNaturalist_CNN_Sweep/runs/s1w7lggt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | activation_fn | GELU             | 0      | train\n",
      "1 | conv_blocks   | Sequential       | 93.7 K | train\n",
      "2 | classifier    | Sequential       | 33.6 M | train\n",
      "3 | loss_fn       | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------------\n",
      "33.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.7 M    Total params\n",
      "134.604   Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'conv_filters' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'kernel_sizes' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dense_neurons' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_norm' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dropout' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb517590529248159759c8c8a9554924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7c5c620a6e4fd08f55cd891367bc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7d8199d70e00>> (for post_run_cell), with arguments args (<ExecutionResult object at 7d819c18acf0, execution_count=6 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7d819c2b1b80, raw_cell=\"launch_sweep()\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/user/Documents/Books/DA24S019_Assignment_2/Part_A/train2.ipynb#W5sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:565\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:771\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:297\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:224\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    222\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    223\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (_run_job):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1251, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/tmp/ipykernel_355767/4047409174.py\", line 38, in train\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 282, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1458, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1420, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1264, in _try_get_data\n",
      "    raise RuntimeError(\n",
      "RuntimeError: DataLoader worker (pid(s) 366208, 366209) exited unexpectedly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/user/anaconda3/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/agents/pyagent.py\", line 311, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 4132, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 449, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 391, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2106, in finish\n",
      "    return self._finish(exit_code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 2113, in _finish\n",
      "    with telemetry.context(run=self) as tel:\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 749, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/wandb_run.py\", line 762, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py\", line 70, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py\", line 46, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 224, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/user/anaconda3/lib/python3.12/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "launch_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
