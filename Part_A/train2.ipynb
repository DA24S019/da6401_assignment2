{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "from Dataset import Nature12KDataModule\n",
    "from cnn_model import CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nature12KDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"data\", batch_size=64, image_size=(512, 512), data_aug=False):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.data_aug = data_aug\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if os.path.exists(self.data_dir):\n",
    "            print(\"✅ Dataset already prepared.\")\n",
    "            return\n",
    "\n",
    "        zip_path = \"iNaturalist.zip\"\n",
    "        url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(\"📥 Downloading dataset...\")\n",
    "            subprocess.run([\"curl\", \"-o\", zip_path, \"-L\", url], check=True)\n",
    "        else:\n",
    "            print(\"✅ Zip file already exists.\")\n",
    "\n",
    "        print(\"📦 Extracting dataset...\")\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        os.rename(\"inaturalist_12K\", self.data_dir)\n",
    "        os.rename(os.path.join(self.data_dir, \"val\"), os.path.join(self.data_dir, \"test\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_transform(image_size, data_aug=False):\n",
    "        transform_list = [transforms.Resize(image_size)]\n",
    "\n",
    "        if data_aug:\n",
    "            transform_list += [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "            ]\n",
    "\n",
    "        transform_list += [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ]\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_transform = self.get_transform(self.image_size, self.data_aug)\n",
    "        test_transform = self.get_transform(self.image_size, False)\n",
    "\n",
    "        full_train = datasets.ImageFolder(os.path.join(self.data_dir, \"train\"), transform=train_transform)\n",
    "        test_set = datasets.ImageFolder(os.path.join(self.data_dir, \"test\"), transform=test_transform)\n",
    "\n",
    "        val_size = int(0.2 * len(full_train))\n",
    "        train_size = len(full_train) - val_size\n",
    "        self.train_set, self.val_set = random_split(full_train, [train_size, val_size])\n",
    "        self.test_set = test_set\n",
    "        self.class_names = full_train.classes\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 conv_filters,\n",
    "                 kernel_sizes,\n",
    "                 activation,\n",
    "                 dense_neurons,\n",
    "                 num_classes,\n",
    "                 lr,\n",
    "                 batch_norm=False,        # ← ADD THIS\n",
    "                 dropout=0.0):            # ← AND THIS IF NOT PRESENT\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        self.activation_fn = self._get_activation_fn(activation)\n",
    "\n",
    "        # Conv Layers\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        for out_channels, ksize in zip(conv_filters, kernel_sizes):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=ksize, padding=ksize // 2))\n",
    "    \n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "    \n",
    "            layers.append(self._get_activation_fn(activation))\n",
    "            layers.append(nn.MaxPool2d(2, 2))\n",
    "\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout2d(dropout))\n",
    "    \n",
    "            in_channels = out_channels\n",
    "\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(*layers)\n",
    "\n",
    "        # Flattened dim\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_channels, 128, 128)\n",
    "            dummy_output = self.conv_blocks(dummy_input)\n",
    "            flatten_dim = dummy_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Fully connected\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(flatten_dim, dense_neurons),\n",
    "            self.activation_fn,\n",
    "            nn.Linear(dense_neurons, num_classes)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def _get_activation_fn(self, name):\n",
    "        name = name.lower()\n",
    "        if name == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif name == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif name == 'silu':\n",
    "            return nn.SiLU()\n",
    "        elif name == 'mish':\n",
    "            return nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        # self.log(\"test_loss\", loss)\n",
    "        # self.log(\"test_acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 conv_filters,\n",
    "                 kernel_sizes,\n",
    "                 activation,\n",
    "                 dense_neurons,\n",
    "                 num_classes,\n",
    "                 lr,\n",
    "                 batch_norm=False,        # ← ADD THIS\n",
    "                 dropout=0.0):            # ← AND THIS IF NOT PRESENT\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        self.activation_fn = self._get_activation_fn(activation)\n",
    "\n",
    "        # Conv Layers\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        for out_channels, ksize in zip(conv_filters, kernel_sizes):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=ksize, padding=ksize // 2))\n",
    "    \n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "    \n",
    "            layers.append(self._get_activation_fn(activation))\n",
    "            layers.append(nn.MaxPool2d(2, 2))\n",
    "\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout2d(dropout))\n",
    "    \n",
    "            in_channels = out_channels\n",
    "\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(*layers)\n",
    "\n",
    "        # Flattened dim\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_channels, 128, 128)\n",
    "            dummy_output = self.conv_blocks(dummy_input)\n",
    "            flatten_dim = dummy_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Fully connected\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(flatten_dim, dense_neurons),\n",
    "            self.activation_fn,\n",
    "            nn.Linear(dense_neurons, num_classes)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def _get_activation_fn(self, name):\n",
    "        name = name.lower()\n",
    "        if name == 'relu':\n",
    "            return nn.ReLU()\n",
    "        elif name == 'gelu':\n",
    "            return nn.GELU()\n",
    "        elif name == 'silu':\n",
    "            return nn.SiLU()\n",
    "        elif name == 'mish':\n",
    "            return nn.Mish()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        # self.log(\"test_loss\", loss)\n",
    "        # self.log(\"test_acc\", acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_sweep():\n",
    "    \n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': 'val_acc',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'conv_filters': {\n",
    "                'values': [\n",
    "                    [32, 64, 128, 256, 512,512],\n",
    "                    # [64, 128, 256, 512,1024],\n",
    "                    # [32, 32, 32, 32, 32],\n",
    "                    # [64, 64, 64, 64, 64]\n",
    "                ]\n",
    "            },\n",
    "            'kernel_sizes': {\n",
    "                'values': [\n",
    "                    [3, 3, 3, 3, 3,3],    \n",
    "                ]\n",
    "            },\n",
    "            'activation': {\n",
    "                'values': ['relu', 'gelu', 'silu', 'mish']\n",
    "            },\n",
    "            'dense_neurons': {\n",
    "                'values': [256]\n",
    "            },\n",
    "            'lr': {\n",
    "                'min': 0.0001,\n",
    "                'max': 0.1\n",
    "            },\n",
    "            'batch_norm': {\n",
    "                'values': [True, False]\n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.2, 0.3]\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [16,32]\n",
    "            },\n",
    "            'data_augmentation': {\n",
    "                'values': [True, False]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    sweep_id = wandb.sweep(sweep_config, project='iNaturalist_CNN_Sweep')\n",
    "    wandb.agent(sweep_id, function=train, count=100)\n",
    "    # 6mpxfky1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def visualize_predictions(model, dataloader, class_names, num_images=30):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "    rows, cols = 10, 3\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 4, rows * 2.5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    transform = transforms.ToPILImage()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            logits = model(x.to(model.device))\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            for img, label, pred in zip(x, y, preds):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                img = transform(img.cpu())\n",
    "                axs[images_shown].imshow(img)\n",
    "                axs[images_shown].axis('off')\n",
    "                axs[images_shown].set_title(f\"True: {class_names[label]}\\nPred: {class_names[pred]}\")\n",
    "                images_shown += 1\n",
    "\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"test_predictions_grid.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def visualize_predictions(model, dataloader, class_names, num_images=30):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "    rows, cols = 10, 3\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 4, rows * 2.5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    transform = transforms.ToPILImage()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            logits = model(x.to(model.device))\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            for img, label, pred in zip(x, y, preds):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                img = transform(img.cpu())\n",
    "                axs[images_shown].imshow(img)\n",
    "                axs[images_shown].axis('off')\n",
    "                axs[images_shown].set_title(f\"True: {class_names[label]}\\nPred: {class_names[pred]}\")\n",
    "                images_shown += 1\n",
    "\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"test_predictions_grid.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model():\n",
    "    # Define best config manually\n",
    "    config = {\n",
    "        \"activation\": \"silu\",\n",
    "        \"batch_norm\": True,\n",
    "        \"batch_size\": 32,\n",
    "        \"data_augmentation\": True,\n",
    "        \"dense_neurons\": 256,\n",
    "        \"dropout\": 0.3,\n",
    "        \"input_channels\": 3,\n",
    "        \"lr\": 0.0004165458022262786,\n",
    "        \"num_classes\": 10,\n",
    "        \"conv_filters\": [32, 64, 128, 128, 128],\n",
    "        \"kernel_sizes\": [3, 3, 3, 3, 3]\n",
    "    }\n",
    "\n",
    "    # Init datamodule\n",
    "    data_module = Nature12KDataModule(\n",
    "        data_dir=\"../../inaturalist_12K\",\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        image_size=(128, 128),\n",
    "        data_aug=config[\"data_augmentation\"]\n",
    "    )\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup()\n",
    "\n",
    "    # Build model with best hyperparameters\n",
    "    model = CNN(\n",
    "        input_channels=config[\"input_channels\"],\n",
    "        conv_filters=config[\"conv_filters\"],\n",
    "        kernel_sizes=config[\"kernel_sizes\"],\n",
    "        activation=config[\"activation\"],\n",
    "        dense_neurons=config[\"dense_neurons\"],\n",
    "        num_classes=config[\"num_classes\"],\n",
    "        lr=config[\"lr\"],\n",
    "        batch_norm=config[\"batch_norm\"],\n",
    "        dropout=config[\"dropout\"]\n",
    "    )\n",
    "\n",
    "    # Optional: disable wandb logging if not needed\n",
    "    wandb_logger = WandbLogger(project=\"best_model_eval\", name=\"Best_CNN_Model\")\n",
    "\n",
    "    # Train the model\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        log_every_n_steps=10,\n",
    "        logger=wandb_logger\n",
    "    )\n",
    "\n",
    "    print(\"🚀 Training best model...\")\n",
    "    trainer.fit(model, data_module.train_dataloader(), data_module.val_dataloader())\n",
    "\n",
    "    print(\"🧪 Evaluating best model on test set...\")\n",
    "    trainer.test(model, data_module.test_dataloader())\n",
    "\n",
    "    return model, data_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data_module = train_best_model()\n",
    "\n",
    "visualize_predictions(model, data_module.test_dataloader(), data_module.class_names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
