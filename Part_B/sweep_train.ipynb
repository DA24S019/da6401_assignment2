{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import os\n",
    "from Dataset import Nature12KDataModule\n",
    "from ResNet import ResNetFinetune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62827f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    data_module = Nature12KDataModule(\n",
    "        data_dir=\"../../inaturalist_12K\",\n",
    "        batch_size=config.batch_size,\n",
    "        image_size=(config.image_size, config.image_size),\n",
    "        data_aug=config.data_augmentation\n",
    "    )\n",
    "\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup()\n",
    "\n",
    "    model = ResNetFinetune(\n",
    "        num_classes=len(data_module.class_names),\n",
    "        lr=config.lr,\n",
    "        optimizer=config.optimizer,\n",
    "        momentum=config.momentum,\n",
    "        weight_decay=config.weight_decay,\n",
    "        scheduler=config.scheduler,\n",
    "        freeze_type=config.freeze_type,\n",
    "        freeze_upto_layer=config.freeze_upto_layer,\n",
    "        resnet_variant=config.resnet_variant\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(project=wandb.run.project, name=wandb.run.name)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        log_every_n_steps=10,\n",
    "        logger=wandb_logger\n",
    "    )\n",
    "\n",
    "    print(\"ðŸš€ Training model...\")\n",
    "    trainer.fit(model, data_module.train_dataloader(), data_module.val_dataloader())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25221535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_sweep():\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {\n",
    "            'name': 'val_acc',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'lr': {'min': 1e-5, 'max': 1e-2},  # Narrower range for fine-tuning\n",
    "            'momentum': {'min': 0.8, 'max': 0.99},  # Higher momentum often helps convergence\n",
    "            'batch_size': {'values': [32, 64]},  # Try larger batch if memory allows\n",
    "            'freeze_type': {'values': ['none', 'upto']},  # 'all' typically underperforms in deeper models\n",
    "            'freeze_upto_layer': {'values': [3, 5, 6, 7]},  # Deeper freezing for larger networks\n",
    "            'data_augmentation': {'values': [True]},  # Always augment for fine-tuning on iNaturalist\n",
    "            'resnet_variant': {'values': ['resnet101']},  # Using ResNet101 (closest to ResNet150)\n",
    "            'weight_decay': {'min': 0.0001, 'max': 0.01},  # Avoid over-regularization\n",
    "            'scheduler': {'values': [True]},  # Learning rate scheduler is typically beneficial\n",
    "            'image_size': {'values': [224, 256, 384]},  # Avoid too large images to prevent OOM\n",
    "            'max_epochs': {'values': [10, 15, 20]},  # Longer training improves accuracy\n",
    "            'optimizer': {'values': ['sgd']}  # Best for large pretrained models like ResNet\n",
    "        }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config, project='iNaturalist_ResNet_Sweep')\n",
    "    wandb.agent(sweep_id, function=train, count=100)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
